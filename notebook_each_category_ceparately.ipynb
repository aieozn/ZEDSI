{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "scheduled-efficiency",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separate-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-standing",
   "metadata": {},
   "source": [
    "### Define const values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brutal-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = 256\n",
    "datadir = 'dataset/'\n",
    "\n",
    "train_set_size = 0.7\n",
    "\n",
    "categories = [\n",
    "    \"loop_scattering\",\n",
    "    \"background_ring\",\n",
    "    \"strong_background\",\n",
    "    \"diffuse_scattering\",\n",
    "    \"artifact\",\n",
    "    \"ice_ring\",\n",
    "    \"non_uniform_detector\"\n",
    "]\n",
    "\n",
    "# categories = [\n",
    "#     \"loop_scattering\"\n",
    "# ]\n",
    "\n",
    "conv_2d_size = 3\n",
    "conv_2d_activation = 'relu'\n",
    "pooling_2d_size = 5\n",
    "loss = 'binary_crossentropy'\n",
    "batch_size = 300                            # Ilość obrazów wrzucanych jednorarazowo do sieci\n",
    "epochs = 20\n",
    "dense_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-abuse",
   "metadata": {},
   "source": [
    "### Load images meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "general-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_META = {}\n",
    "TEST_DATA_ORDER = []\n",
    "\n",
    "def num_to_bool(text):\n",
    "    if text == \"0\":\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1.\n",
    "\n",
    "with open('train.csv', newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        image_categories = []\n",
    "        \n",
    "        for category in categories:\n",
    "            image_categories.append(num_to_bool(row[category]))\n",
    "            \n",
    "        IMAGES_META[row[\"image\"]] = image_categories\n",
    "\n",
    "with open('test.csv', newline='') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        TEST_DATA_ORDER.append(row[\"image\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-roots",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (5048, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "IMAGES = []\n",
    "LABELS = [[] for x in range(len(categories))]\n",
    "\n",
    "COMPETITION_IMAGES = []\n",
    "COMPETITION_IMAGES_NAMES = []\n",
    "\n",
    "def get_category_cum(name):\n",
    "    for num, category in enumerate(categories):\n",
    "        if category == name:\n",
    "            return num\n",
    "\n",
    "\n",
    "for img in os.listdir(datadir):\n",
    "    image = Image.open(datadir + img).convert(\"L\")\n",
    "\n",
    "    ii = image.resize((img_size,img_size), Image.BICUBIC)\n",
    "    arr = np.asarray(ii)  / 255.0\n",
    "    \n",
    "    anomalies = IMAGES_META.get(img.replace(\".png\", \"\"))\n",
    "    \n",
    "    if anomalies == None:\n",
    "        # Zdjęcie nie należy do zbioru testowego\n",
    "        COMPETITION_IMAGES.append(arr)\n",
    "        COMPETITION_IMAGES_NAMES.append(img.replace(\".png\", \"\"))\n",
    "        continue\n",
    "\n",
    "    IMAGES.append(arr)\n",
    "    \n",
    "    for x in range(len(categories)):\n",
    "        LABELS[x].append([anomalies[x]])\n",
    "    \n",
    "IMAGES = np.array(IMAGES)\n",
    "COMPETITION_IMAGES = np.array(COMPETITION_IMAGES)\n",
    "IMAGES = IMAGES.reshape(len(IMAGES), img_size, img_size, 1)\n",
    "COMPETITION_IMAGES = COMPETITION_IMAGES.reshape(len(COMPETITION_IMAGES), img_size, img_size, 1)\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    LABELS[x] = np.array(LABELS[x])\n",
    "\n",
    "print(\"Images shape: \", IMAGES.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-running",
   "metadata": {},
   "source": [
    "#### Parametry sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offensive-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for x in range(len(categories)):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (conv_2d_size, conv_2d_size), input_shape = (img_size, img_size, 1), activation = conv_2d_activation)) # input shape -> bardzo wazne zeby odpowiadalo wymiarowi obrazkow - tutaj np. obrazki 64x64 i 3 kanały\n",
    "    model.add(MaxPooling2D(pool_size = (pooling_2d_size, pooling_2d_size)))\n",
    "\n",
    "    model.add(Conv2D(32, (conv_2d_size, conv_2d_size), activation = conv_2d_activation))\n",
    "    model.add(MaxPooling2D(pool_size = (pooling_2d_size, pooling_2d_size)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units = dense_units, activation = 'sigmoid'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sacred-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss = loss,\n",
    "        optimizer = 'Adam',\n",
    "        metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heavy-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podzielenie na grupy\n",
    "train_images_count = int(len(IMAGES) * train_set_size)\n",
    "test_images_count = len(IMAGES) - train_images_count\n",
    "\n",
    "LABELS_TEST = []\n",
    "LABELS_TRAIN = []\n",
    "\n",
    "IMAGES_TRAIN = IMAGES[:train_images_count]\n",
    "IMAGES_TEST = IMAGES[train_images_count:]\n",
    "\n",
    "for x in range(len(categories)):\n",
    "    LABELS_TEST.append(LABELS[x][train_images_count:])\n",
    "    LABELS_TRAIN.append(LABELS[x][:train_images_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bearing-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6873 - accuracy: 0.5923 - val_loss: 0.7263 - val_accuracy: 0.4407\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6678 - accuracy: 0.6018 - val_loss: 0.6995 - val_accuracy: 0.4661\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6408 - accuracy: 0.6455 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6189 - accuracy: 0.6622 - val_loss: 0.6667 - val_accuracy: 0.5113\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5901 - accuracy: 0.6851 - val_loss: 0.6373 - val_accuracy: 0.6469\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5748 - accuracy: 0.6999 - val_loss: 0.6132 - val_accuracy: 0.6469\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5743 - accuracy: 0.7008 - val_loss: 0.6137 - val_accuracy: 0.6497\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5761 - accuracy: 0.7005 - val_loss: 0.6157 - val_accuracy: 0.6836\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5735 - accuracy: 0.6933 - val_loss: 0.6191 - val_accuracy: 0.6751\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5610 - accuracy: 0.7078 - val_loss: 0.6091 - val_accuracy: 0.6751\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.5594 - accuracy: 0.7087 - val_loss: 0.6087 - val_accuracy: 0.6751\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.5534 - accuracy: 0.7125 - val_loss: 0.6192 - val_accuracy: 0.6667\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6972 - accuracy: 0.5225 - val_loss: 0.6960 - val_accuracy: 0.3418\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6873 - accuracy: 0.5332 - val_loss: 0.6537 - val_accuracy: 0.6949\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6758 - accuracy: 0.5845 - val_loss: 0.6322 - val_accuracy: 0.6893\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6628 - accuracy: 0.5983 - val_loss: 0.6253 - val_accuracy: 0.6808\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6535 - accuracy: 0.6049 - val_loss: 0.6342 - val_accuracy: 0.6723\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6443 - accuracy: 0.6235 - val_loss: 0.6119 - val_accuracy: 0.7062\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6306 - accuracy: 0.6414 - val_loss: 0.5991 - val_accuracy: 0.7345\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6157 - accuracy: 0.6732 - val_loss: 0.5671 - val_accuracy: 0.7232\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6031 - accuracy: 0.6773 - val_loss: 0.5614 - val_accuracy: 0.7345\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.6009 - accuracy: 0.6691 - val_loss: 0.5509 - val_accuracy: 0.7175\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 35s 3s/step - loss: 0.5858 - accuracy: 0.7021 - val_loss: 0.5549 - val_accuracy: 0.7514\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.5740 - accuracy: 0.7106 - val_loss: 0.5411 - val_accuracy: 0.7655\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.6856 - accuracy: 0.5709 - val_loss: 0.7347 - val_accuracy: 0.3616\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6230 - accuracy: 0.5826 - val_loss: 0.6585 - val_accuracy: 0.5085\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.4862 - accuracy: 0.8282 - val_loss: 0.4317 - val_accuracy: 0.7938\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.3635 - accuracy: 0.8496 - val_loss: 0.3521 - val_accuracy: 0.8333\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.3112 - accuracy: 0.8663 - val_loss: 0.3164 - val_accuracy: 0.8446\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2959 - accuracy: 0.8779 - val_loss: 0.2860 - val_accuracy: 0.8757\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.2803 - accuracy: 0.8839 - val_loss: 0.2740 - val_accuracy: 0.8842\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2731 - accuracy: 0.8861 - val_loss: 0.2749 - val_accuracy: 0.8757\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2676 - accuracy: 0.8918 - val_loss: 0.2742 - val_accuracy: 0.8757\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2684 - accuracy: 0.8912 - val_loss: 0.2542 - val_accuracy: 0.8898\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2517 - accuracy: 0.8981 - val_loss: 0.2707 - val_accuracy: 0.8701\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.2490 - accuracy: 0.9009 - val_loss: 0.2425 - val_accuracy: 0.8898\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 35s 3s/step - loss: 0.4429 - accuracy: 0.7773 - val_loss: 0.4560 - val_accuracy: 0.9096\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.3023 - accuracy: 0.9286 - val_loss: 0.3137 - val_accuracy: 0.9096\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2631 - accuracy: 0.9286 - val_loss: 0.3180 - val_accuracy: 0.9096\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2614 - accuracy: 0.9286 - val_loss: 0.3058 - val_accuracy: 0.9096\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2564 - accuracy: 0.9286 - val_loss: 0.3027 - val_accuracy: 0.9096\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2550 - accuracy: 0.9286 - val_loss: 0.3037 - val_accuracy: 0.9096\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2495 - accuracy: 0.9286 - val_loss: 0.3002 - val_accuracy: 0.9096\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2471 - accuracy: 0.9286 - val_loss: 0.2998 - val_accuracy: 0.9096\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2483 - accuracy: 0.9286 - val_loss: 0.2943 - val_accuracy: 0.9096\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2427 - accuracy: 0.9286 - val_loss: 0.2900 - val_accuracy: 0.9096\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2386 - accuracy: 0.9286 - val_loss: 0.2858 - val_accuracy: 0.9096\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2340 - accuracy: 0.9286 - val_loss: 0.2901 - val_accuracy: 0.9096\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.5265 - accuracy: 0.7936 - val_loss: 0.3182 - val_accuracy: 0.9492\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.4964 - accuracy: 0.7936 - val_loss: 0.2614 - val_accuracy: 0.9492\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.4687 - accuracy: 0.7940 - val_loss: 0.2541 - val_accuracy: 0.9379\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.4612 - accuracy: 0.8012 - val_loss: 0.2326 - val_accuracy: 0.9379\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.4525 - accuracy: 0.8040 - val_loss: 0.2262 - val_accuracy: 0.9407\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.4481 - accuracy: 0.8128 - val_loss: 0.2460 - val_accuracy: 0.9379\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.4393 - accuracy: 0.8204 - val_loss: 0.2308 - val_accuracy: 0.9435\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4346 - accuracy: 0.8220 - val_loss: 0.2458 - val_accuracy: 0.9435\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4261 - accuracy: 0.8257 - val_loss: 0.2270 - val_accuracy: 0.9463\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.4288 - accuracy: 0.8311 - val_loss: 0.2513 - val_accuracy: 0.9407\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 30s 3s/step - loss: 0.4160 - accuracy: 0.8323 - val_loss: 0.2381 - val_accuracy: 0.9463\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4038 - accuracy: 0.8421 - val_loss: 0.2207 - val_accuracy: 0.9435\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.3098 - accuracy: 0.9232 - val_loss: 0.3018 - val_accuracy: 0.9124\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.2739 - accuracy: 0.9232 - val_loss: 0.3047 - val_accuracy: 0.9124\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2730 - accuracy: 0.9232 - val_loss: 0.3005 - val_accuracy: 0.9124\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2694 - accuracy: 0.9232 - val_loss: 0.3019 - val_accuracy: 0.9124\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2681 - accuracy: 0.9232 - val_loss: 0.3020 - val_accuracy: 0.9124\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2672 - accuracy: 0.9232 - val_loss: 0.2997 - val_accuracy: 0.9124\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2632 - accuracy: 0.9232 - val_loss: 0.3079 - val_accuracy: 0.9124\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2608 - accuracy: 0.9232 - val_loss: 0.2958 - val_accuracy: 0.9124\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2521 - accuracy: 0.9232 - val_loss: 0.2889 - val_accuracy: 0.9124\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2451 - accuracy: 0.9229 - val_loss: 0.2751 - val_accuracy: 0.9124\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2411 - accuracy: 0.9245 - val_loss: 0.2713 - val_accuracy: 0.9124\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2315 - accuracy: 0.9245 - val_loss: 0.2574 - val_accuracy: 0.9124\n",
      "Epoch 1/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6763 - accuracy: 0.6024 - val_loss: 0.6947 - val_accuracy: 0.5791\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6685 - accuracy: 0.6024 - val_loss: 0.6901 - val_accuracy: 0.5791\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6588 - accuracy: 0.6024 - val_loss: 0.6790 - val_accuracy: 0.5791\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.6484 - accuracy: 0.6024 - val_loss: 0.6948 - val_accuracy: 0.5791\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6354 - accuracy: 0.6077 - val_loss: 0.6815 - val_accuracy: 0.5339\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6333 - accuracy: 0.6153 - val_loss: 0.7295 - val_accuracy: 0.5791\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6248 - accuracy: 0.6241 - val_loss: 0.7329 - val_accuracy: 0.5819\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6164 - accuracy: 0.6364 - val_loss: 0.7310 - val_accuracy: 0.5734\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6171 - accuracy: 0.6351 - val_loss: 0.6841 - val_accuracy: 0.5734\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6144 - accuracy: 0.6546 - val_loss: 0.7045 - val_accuracy: 0.5565\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6019 - accuracy: 0.6477 - val_loss: 0.6908 - val_accuracy: 0.5819\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.5952 - accuracy: 0.6615 - val_loss: 0.6908 - val_accuracy: 0.5706\n"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "\n",
    "for category_num, category in enumerate(categories):\n",
    "    \n",
    "    hist.append(models[category_num].fit(\n",
    "        IMAGES_TRAIN,\n",
    "        LABELS_TRAIN[category_num],\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_split = 0.1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advisory-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 5s 99ms/step - loss: 0.5931 - accuracy: 0.7069\n",
      "48/48 [==============================] - 5s 100ms/step - loss: 0.4829 - accuracy: 0.7941\n",
      "48/48 [==============================] - 5s 100ms/step - loss: 0.2832 - accuracy: 0.8858\n",
      "48/48 [==============================] - 5s 100ms/step - loss: 0.2647 - accuracy: 0.9307\n",
      "48/48 [==============================] - 5s 101ms/step - loss: 0.2198 - accuracy: 0.9347\n",
      "48/48 [==============================] - 5s 102ms/step - loss: 0.2271 - accuracy: 0.9300\n",
      "48/48 [==============================] - 5s 98ms/step - loss: 0.5446 - accuracy: 0.7954\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "if test_images_count > 0:\n",
    "    \n",
    "    for x in range(len(categories)):\n",
    "        models[x].evaluate(IMAGES_TEST, LABELS_TEST[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "built-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "total_labels = 0\n",
    "\n",
    "if test_images_count > 0:\n",
    "    hamming_loss = 0\n",
    "\n",
    "    def xor_sum(N, L):\n",
    "        total = 0\n",
    "\n",
    "        for x in range(len(N)):\n",
    "            if N[x] != L[x]:\n",
    "                total += 1\n",
    "\n",
    "        return total\n",
    "\n",
    "    total = 0\n",
    "\n",
    "    categories_results = [0 for x in range(len(categories))]\n",
    "    categories_false_positive = [0 for x in range(len(categories))]\n",
    "    categories_true_negetive = [0 for x in range(len(categories))]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for x in range(len(categories)):\n",
    "        predictions.append(models[x].predict(IMAGES_TEST))\n",
    "\n",
    "    for num in range(len(IMAGES_TEST)):\n",
    "\n",
    "        prediction = []\n",
    "        valid = []\n",
    "        \n",
    "        for x in range(len(categories)):\n",
    "            prediction.append(predictions[x][num])\n",
    "            \n",
    "            if (prediction[x] > thresholds[x]):\n",
    "                prediction[x] = 1\n",
    "            else:\n",
    "                prediction[x] = 0\n",
    "            \n",
    "            total_labels += 1\n",
    "            \n",
    "            valid.append(round(LABELS_TEST[x][num][0]))\n",
    "\n",
    "        total += xor_sum(valid, prediction)\n",
    "\n",
    "        for identifier, (valid_response, predicted_response) in enumerate(zip(valid, prediction)):\n",
    "            \n",
    "            if predicted_response == 1 and valid_response == 0:\n",
    "                categories_false_positive[identifier] += 1\n",
    "            elif predicted_response == 0 and valid_response == 1:\n",
    "                categories_true_negetive[identifier] += 1\n",
    "                \n",
    "            if valid_response == predicted_response:\n",
    "                categories_results[identifier] += 1\n",
    "\n",
    "    categories_results = [x / len(IMAGES_TEST) for x in categories_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indoor-truck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Convolution 2D size:  3\n",
      "- Convolution 2D activation:  relu\n",
      "- Pooling 2D size:  5\n",
      "- Loss function:  binary_crossentropy\n",
      "- Batch size:  300\n",
      "- Epochs:  12\n",
      "- Dense units:  128\n"
     ]
    }
   ],
   "source": [
    "print(\"- Convolution 2D size: \", conv_2d_size)\n",
    "print(\"- Convolution 2D activation: \", conv_2d_activation)\n",
    "print(\"- Pooling 2D size: \", pooling_2d_size)\n",
    "print(\"- Loss function: \", loss)\n",
    "print(\"- Batch size: \", batch_size)\n",
    "print(\"- Epochs: \", epochs)\n",
    "print(\"- Dense units: \", dense_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mighty-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming_loss = 0.14606317774634606\n",
      "categories_results = [0.7069306930693069, 0.7940594059405941, 0.8858085808580858, 0.9306930693069307, 0.9346534653465347, 0.93003300330033, 0.7953795379537953]\n",
      "categories_false_positives = [195, 212, 72, 0, 0, 0, 88]\n",
      "categories_true_negatives = [249, 100, 101, 105, 99, 106, 222]\n",
      "categories = ['loop_scattering', 'background_ring', 'strong_background', 'diffuse_scattering', 'artifact', 'ice_ring', 'non_uniform_detector']\n"
     ]
    }
   ],
   "source": [
    "print(\"hamming_loss =\", total / total_labels)\n",
    "print(\"categories_results =\", categories_results)\n",
    "print(\"categories_false_positives =\", categories_false_positive)\n",
    "print(\"categories_true_negatives =\", categories_true_negetive)\n",
    "print(\"categories =\", categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-highland",
   "metadata": {},
   "source": [
    "# Generowanie wyników do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respiratory-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = 0\n",
    "unordered_data = {}\n",
    "\n",
    "predictions = []\n",
    "for num in enumerate(categories):\n",
    "    predictions.append(models[x].predict(COMPETITION_IMAGES))\n",
    "    \n",
    "for image_num in range(len(COMPETITION_IMAGES)):\n",
    "        prediction = []\n",
    "        \n",
    "        for num in range(len(categories)):\n",
    "            prediction.append(predictions[num][image_num])\n",
    "            \n",
    "            if (prediction[num] > thresholds[num]):\n",
    "                prediction[num] = 1\n",
    "            else:\n",
    "                prediction[num] = 0\n",
    "        \n",
    "        for annomaly_num, annomaly in enumerate(categories):\n",
    "            if unordered_data.get(COMPETITION_IMAGES_NAMES[image_num]) is None:\n",
    "                unordered_data[COMPETITION_IMAGES_NAMES[image_num]] = []\n",
    "            \n",
    "            unordered_data[COMPETITION_IMAGES_NAMES[image_num]].append(\n",
    "                {\n",
    "                    'id': row_num,\n",
    "                    'image': COMPETITION_IMAGES_NAMES[image_num],\n",
    "                    'anomaly': annomaly,\n",
    "                    'predicted': prediction[annomaly_num]\n",
    "                })\n",
    "            row_num += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "forced-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_loop_scattering = [0.6873069405555725, 0.6678471565246582, 0.6408314108848572, 0.6188585758209229, 0.5901282429695129, 0.5747758746147156, 0.5742760896682739, 0.5761433839797974, 0.5734609365463257, 0.560977578163147, 0.5594135522842407, 0.5534055233001709]\n",
      "accuracy_loop_scattering = [0.5923246145248413, 0.6017615795135498, 0.6454859972000122, 0.6621578931808472, 0.6851211190223694, 0.6999056339263916, 0.7008492946624756, 0.7005347609519958, 0.6932997703552246, 0.7077697515487671, 0.7087134122848511, 0.7124881744384766]\n",
      "val_loss_loop_scattering = [0.7263337969779968, 0.6994538307189941, 0.6824160814285278, 0.66669762134552, 0.637310266494751, 0.613245964050293, 0.6136537194252014, 0.6157262921333313, 0.6191288232803345, 0.6090585589408875, 0.6086792945861816, 0.6191533207893372]\n",
      "val_accuracy_loop_scattering = [0.4406779706478119, 0.4661017060279846, 0.5, 0.5112994313240051, 0.6468926668167114, 0.6468926668167114, 0.6497175097465515, 0.6836158037185669, 0.6751412153244019, 0.6751412153244019, 0.6751412153244019, 0.6666666865348816]\n",
      "loss_background_ring = [0.6971569061279297, 0.6873489618301392, 0.6758447885513306, 0.6627982258796692, 0.6534759998321533, 0.6442687511444092, 0.6305604577064514, 0.6156549453735352, 0.6031414866447449, 0.6008856892585754, 0.5858033895492554, 0.5740112662315369]\n",
      "accuracy_background_ring = [0.5224913358688354, 0.5331865549087524, 0.5844604969024658, 0.598301351070404, 0.604907214641571, 0.6234664916992188, 0.6413966417312622, 0.6731676459312439, 0.6772570013999939, 0.6690783500671387, 0.7021076083183289, 0.7106007933616638]\n",
      "val_loss_background_ring = [0.6960247755050659, 0.6536931395530701, 0.6321813464164734, 0.6253378987312317, 0.6342046856880188, 0.6118761301040649, 0.5991389751434326, 0.5670708417892456, 0.5613704919815063, 0.5508530735969543, 0.5548805594444275, 0.5410794019699097]\n",
      "val_accuracy_background_ring = [0.34180790185928345, 0.694915235042572, 0.6892655491828918, 0.6807909607887268, 0.6723163723945618, 0.7062146663665771, 0.7344632744789124, 0.7231638431549072, 0.7344632744789124, 0.7175140976905823, 0.7514124512672424, 0.7655367255210876]\n",
      "loss_strong_background = [0.6855879426002502, 0.6229702234268188, 0.48622485995292664, 0.36352622509002686, 0.3111768364906311, 0.2958742380142212, 0.2802932560443878, 0.27313363552093506, 0.2675798833370209, 0.268388569355011, 0.2517174184322357, 0.2489721029996872]\n",
      "accuracy_strong_background = [0.5709342360496521, 0.5825731158256531, 0.8282479047775269, 0.8496382236480713, 0.866310179233551, 0.877949059009552, 0.88392573595047, 0.8861277103424072, 0.8917898535728455, 0.8911607265472412, 0.8980811834335327, 0.9009122252464294]\n",
      "val_loss_strong_background = [0.7346519827842712, 0.6584677696228027, 0.4316652715206146, 0.3521481454372406, 0.316360741853714, 0.2859976291656494, 0.27395713329315186, 0.2749116122722626, 0.2741629481315613, 0.2542065680027008, 0.2706553041934967, 0.24247248470783234]\n",
      "val_accuracy_strong_background = [0.3615819215774536, 0.508474588394165, 0.7937853336334229, 0.8333333134651184, 0.8446327447891235, 0.8757061958312988, 0.8841807842254639, 0.8757061958312988, 0.8757061958312988, 0.8898305296897888, 0.8700565099716187, 0.8898305296897888]\n",
      "loss_diffuse_scattering = [0.44285789132118225, 0.30228179693222046, 0.2630872130393982, 0.2613581120967865, 0.25636032223701477, 0.2549979090690613, 0.2494712620973587, 0.24706803262233734, 0.24829715490341187, 0.2427055835723877, 0.23861059546470642, 0.23396265506744385]\n",
      "accuracy_diffuse_scattering = [0.7772884368896484, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611, 0.9285938739776611]\n",
      "val_loss_diffuse_scattering = [0.45598021149635315, 0.3137483596801758, 0.31803733110427856, 0.3057941198348999, 0.30272045731544495, 0.30370908975601196, 0.30017536878585815, 0.2998243570327759, 0.29433825612068176, 0.29004794359207153, 0.28576821088790894, 0.29008322954177856]\n",
      "val_accuracy_diffuse_scattering = [0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959, 0.909604549407959]\n",
      "loss_artifact = [0.5265498757362366, 0.4963572323322296, 0.468652606010437, 0.46121540665626526, 0.4525400698184967, 0.448114275932312, 0.4392962157726288, 0.4345625936985016, 0.42606955766677856, 0.4288090765476227, 0.41599008440971375, 0.4038463532924652]\n",
      "accuracy_artifact = [0.7936457991600037, 0.7936457991600037, 0.7939603924751282, 0.8011953234672546, 0.8040264248847961, 0.8128342032432556, 0.8203837871551514, 0.8219565749168396, 0.8257313370704651, 0.8310789465904236, 0.8323372006416321, 0.8420886993408203]\n",
      "val_loss_artifact = [0.31818169355392456, 0.26137739419937134, 0.2541067600250244, 0.23255394399166107, 0.22618502378463745, 0.24596469104290009, 0.23076090216636658, 0.24580010771751404, 0.22696936130523682, 0.2513304352760315, 0.2380756437778473, 0.2206517606973648]\n",
      "val_accuracy_artifact = [0.9491525292396545, 0.9491525292396545, 0.9378530979156494, 0.9378530979156494, 0.9406779408454895, 0.9378530979156494, 0.9435028433799744, 0.9435028433799744, 0.9463276863098145, 0.9406779408454895, 0.9463276863098145, 0.9435028433799744]\n",
      "loss_ice_ring = [0.30984431505203247, 0.27388840913772583, 0.2729603052139282, 0.26943156123161316, 0.26808467507362366, 0.2671924829483032, 0.2631801664829254, 0.2607855498790741, 0.2520974576473236, 0.24512256681919098, 0.2411128431558609, 0.23149757087230682]\n",
      "accuracy_ice_ring = [0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9232463240623474, 0.9229317307472229, 0.9245045781135559, 0.9245045781135559]\n",
      "val_loss_ice_ring = [0.30178263783454895, 0.3047046959400177, 0.30046436190605164, 0.3019459545612335, 0.30200880765914917, 0.299716055393219, 0.30791589617729187, 0.2957990765571594, 0.2888542115688324, 0.27510058879852295, 0.27129000425338745, 0.25743240118026733]\n",
      "val_accuracy_ice_ring = [0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991, 0.9124293923377991]\n",
      "loss_non_uniform_detector = [0.6762622594833374, 0.668455958366394, 0.6587579250335693, 0.6483885049819946, 0.635403037071228, 0.6333313584327698, 0.624777615070343, 0.6163839101791382, 0.6171371340751648, 0.6144194006919861, 0.601855456829071, 0.5952397584915161]\n",
      "accuracy_non_uniform_detector = [0.602390706539154, 0.602390706539154, 0.602390706539154, 0.602390706539154, 0.6077382564544678, 0.6152878403663635, 0.624095618724823, 0.6363636255264282, 0.6351053714752197, 0.6546083688735962, 0.6476879715919495, 0.6615287661552429]\n",
      "val_loss_non_uniform_detector = [0.6947273015975952, 0.6900556683540344, 0.6789591312408447, 0.6947529911994934, 0.6814958453178406, 0.729516863822937, 0.7328882813453674, 0.730981707572937, 0.6841099858283997, 0.7044922113418579, 0.6907613277435303, 0.690805971622467]\n",
      "val_accuracy_non_uniform_detector = [0.5790960192680359, 0.5790960192680359, 0.5790960192680359, 0.5790960192680359, 0.5338982939720154, 0.5790960192680359, 0.5819209218025208, 0.5734463334083557, 0.5734463334083557, 0.5564971566200256, 0.5819209218025208, 0.5706214904785156]\n"
     ]
    }
   ],
   "source": [
    "for num, his in enumerate(hist):\n",
    "    print(\"loss_\" + categories[num], \"=\", his.history[\"loss\"])\n",
    "    print(\"accuracy_\" + categories[num], \"=\", his.history[\"accuracy\"])\n",
    "    print(\"val_loss_\" + categories[num], \"=\", his.history[\"val_loss\"])\n",
    "    print(\"val_accuracy_\" + categories[num], \"=\", his.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_num = 1\n",
    "# with open('submission.csv', 'w', newline='') as csvfile:\n",
    "#     spamwriter = csv.DictWriter(csvfile, fieldnames=[\"id\",\"image\",\"anomaly\",\"predicted\"])\n",
    "#     spamwriter.writeheader()\n",
    "    \n",
    "#     for image_name in TEST_DATA_ORDER:\n",
    "#         for result_row in unordered_data[image_name]:\n",
    "#             result_row[\"id\"] = row_num\n",
    "#             spamwriter.writerow(result_row)\n",
    "#             row_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
